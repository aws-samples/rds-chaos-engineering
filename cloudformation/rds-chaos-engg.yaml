## Amazon Aurora Fault Injection Workshop
## Infrastructure template with an Aurora cluster for lab exercises
##
##
## Dependencies:
## none
##
## License:
## This sample code is made available under the MIT-0 license. See the LICENSE file.
##

AWSTemplateFormatVersion: 2010-09-09
Description: Amazon Aurora Fault Injection Workshop


## Parameters
Parameters:
  IsWorkshopStudioEnv:
    Type: String
    Default: "yes"
    AllowedValues:
      - "no"
      - "yes"
    Description: Whether this stack is being deployed in a Workshop Studio environment or not. If not sure, leave as default of "no".
  # These two parameters are magic variables, only meant to work with WS studio.
  MyAssetsBucketName:
    Description: Please leave blank, reserved for internal use.
    Type: String
  MyAssetsBucketPrefix:
    Description: Please leave blank, reserved for internal use.
    Type: String
  deployMySQLandPGCluster:
    Default: "no"
    Description: Deployment of Aurora PG cluster is default. Setting this parameter will also deploy AMSv3.
    Type: String
    AllowedValues:
      - "no"
      - "yes"
    Description: Deployment of Aurora PG cluster is default. Setting this parameter will also deploy AMSv3.


  LatestAmiId:
    Type: 'AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>'
    Default: '/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-ebs'
    Description: Please leave as-is, reserved for internal use.
  TemplateName:
    Type: String
    Default: 'auroralab-pg'
    Description: Name used for different elements created.
  CreateInstance:
    Type: String
    Default: "true"
    AllowedValues:
      - "true"
      - "false"
    Description: Determines if Aurora PostgreSQL Cluster needs to be created.
  DBInstanceClass:
    Description: 'The instance type of database server.'
    Type: String
    Default: 'db.r6g.large'
  DBEngineVersion:
    Description: Select Database Engine Version
    Type: String
    Default: 15.3

## Metadata
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Help Us Improve Our Labs!"
      - Label:
          default: "Reserved for Internal Use (Do Not Change)"
        Parameters:
          - LatestAmiId
          - MyAssetsBucketName
          - MyAssetsBucketPrefix
      - Label:
          default: "Lab environment selection"
        Parameters:
          - IsWorkshopStudioEnv
    ParameterLabels:
      LatestAmiId:
        default: "Reference Linux AMI"
      IsWorkshopStudioEnv:
        default: "Are you in a workshop environment provided by AWS instructors?"

Conditions:
  # Are we running in WS? - used to hardcode resource name prefixes when deployed in WS among other things, use the stack name otherwise
  IsWS: !Equals 
    - !Ref IsWorkshopStudioEnv
    - "yes"
  IsMySQL: !Equals
    - !Ref deployMySQLandPGCluster
    - "yes"

## Mappings
Mappings:
  RegionalSettings:
    us-east-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: N. Virginia
      az1: us-east-1a
      az2: us-east-1b
      az3: us-east-1c
    us-east-2:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Ohio
      az1: us-east-2c
      az2: us-east-2a
      az3: us-east-2b
    us-west-2:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Oregon
      az1: us-west-2b
      az2: us-west-2c
      az3: us-west-2d
    ca-central-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Montreal
      az1: ca-central-1d
      az2: ca-central-1a
      az3: ca-central-1b
    eu-central-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Frankfurt
      az1: eu-central-1b
      az2: eu-central-1a
      az3: eu-central-1c
    eu-west-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Ireland
      az1: eu-west-1a
      az2: eu-west-1b
      az3: eu-west-1c
    eu-west-2:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: London
      az1: eu-west-2b
      az2: eu-west-2a
      az3: eu-west-2c
    ap-southeast-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Singapore
      az1: ap-southeast-1c
      az2: ap-southeast-1b
      az3: ap-southeast-1a
    ap-southeast-2:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Sydney
      az1: ap-southeast-2a
      az2: ap-southeast-2b
      az3: ap-southeast-2c
    ap-south-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Mumbai
      az1: ap-south-1a
      az2: ap-south-1b
      az3: ap-south-1c
    ap-northeast-1:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Tokyo
      az1: ap-northeast-1d
      az2: ap-northeast-1a
      az3: ap-northeast-1c
    ap-northeast-2:
      ideType: m5.large
      supersetType: m5.large
      nodeType: db.r6g.large
      name: Seoul
      az1: ap-northeast-2a
      az2: ap-northeast-2b
      az3: ap-northeast-2c
  NetworkSettings:
    primary:
      vpcCidr: 172.30.0.0/16
      subPub1Cidr: 172.30.0.0/24
      subPub2Cidr: 172.30.1.0/24
      subPub3Cidr: 172.30.2.0/24
      subPrv1Cidr: 172.30.10.0/24
      subPrv2Cidr: 172.30.11.0/24
      subPrv3Cidr: 172.30.12.0/24
    secondary:
      vpcCidr: 172.31.0.0/16
      subPub1Cidr: 172.31.0.0/24
      subPub2Cidr: 172.31.1.0/24
      subPub3Cidr: 172.31.2.0/24
      subPrv1Cidr: 172.31.10.0/24
      subPrv2Cidr: 172.31.11.0/24
      subPrv3Cidr: 172.31.12.0/24
  ClusterSettings:
    global:
      dbSchema: mylab
      dbDriver: mysql
      dbVersionAMS3: 8.0.mysql_aurora.3.03.0
      dbEngine: aurora-mysql
      dbFamily: aurora-mysql5.7
      dbFamilyAMS3: aurora-mysql8.0
      pgdbDriver: pgsql
      pgdbFamily: aurora-postgresql15
    sysbench:
      dbSchema: sbtpcc
      runTime: '600'
      numThreads: '4'
      numTables: '8'
      numWarehouses: '2'

## Resources
Resources:

  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Join ['-', ['auroralab-vpc', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]

## The VPC
  vpc:
    Type: "AWS::EC2::VPC"
    Properties:
      EnableDnsSupport: true
      EnableDnsHostnames: true
      InstanceTenancy: default
      CidrBlock: !FindInMap [ NetworkSettings, primary, vpcCidr ] 
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-vpc", !Join ['-', ['auroralab-vpc', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create an IGW & attach it to the VPC
  vpcIgw:
    Type: "AWS::EC2::InternetGateway"
    Properties:
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-igw", !Join ['-', ['auroralab-igw', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  attachIgwVpc:
    Type: "AWS::EC2::VPCGatewayAttachment"
    Properties:
      VpcId: !Ref vpc
      InternetGatewayId: !Ref vpcIgw

## Create a public subnet in each AZ
  sub1Public:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPub1Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az1 ]
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pub-sub-1", !Join ['-', ['auroralab-pub-sub-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  sub2Public:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPub2Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az2 ]
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pub-sub-2",  !Join ['-', ['auroralab-pub-sub-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  sub3Public:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPub3Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az3 ]
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pub-sub-3",  !Join ['-', ['auroralab-pub-sub-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Associate the public subnets with a public route table
  rtbPublic:
    Type: "AWS::EC2::RouteTable"
    Properties:
      VpcId: !Ref vpc
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-public-rtb",  !Join ['-', ['auroralab-public-rtb', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  rteToIgw:
    Type: "AWS::EC2::Route"
    DependsOn: attachIgwVpc
    Properties:
      RouteTableId: !Ref rtbPublic
      DestinationCidrBlock: "0.0.0.0/0"
      GatewayId: !Ref vpcIgw
  srta1Public:
    Type: "AWS::EC2::SubnetRouteTableAssociation"
    Properties:
      SubnetId: !Ref sub1Public
      RouteTableId: !Ref rtbPublic
  srta2Public:
    Type: "AWS::EC2::SubnetRouteTableAssociation"
    Properties:
      SubnetId: !Ref sub2Public
      RouteTableId: !Ref rtbPublic
  srta3Public:
    Type: "AWS::EC2::SubnetRouteTableAssociation"
    Properties:
      SubnetId: !Ref sub3Public
      RouteTableId: !Ref rtbPublic

## Create a private subnet in each AZ
  sub1Private:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPrv1Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az1 ]
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-prv-sub-1", !Join ['-', ['auroralab-prv-sub-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  sub2Private:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPrv2Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az2 ]
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-prv-sub-2", !Join ['-', ['auroralab-prv-sub-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  sub3Private:
    Type: "AWS::EC2::Subnet"
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, primary, subPrv3Cidr ] 
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az3 ]
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-prv-sub-3", !Join ['-', ['auroralab-prv-sub-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create a NAT Gateway & EIP
  natEip:
    Type: "AWS::EC2::EIP"
    Properties:
      Domain: vpc
  vpcNgw:
    Type: "AWS::EC2::NatGateway"
    DependsOn: attachIgwVpc
    Properties:
      AllocationId: !GetAtt natEip.AllocationId
      SubnetId: !Ref sub2Public

## Associate the private subnets with a NATed route table
  rtbNat:
    Type: "AWS::EC2::RouteTable"
    Properties:
      VpcId: !Ref vpc
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-nat-rtb", !Join ['-', ['auroralab-nat-rtb', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  rteToNgw:
    Type: "AWS::EC2::Route"
    Properties:
      RouteTableId: !Ref rtbNat
      DestinationCidrBlock: "0.0.0.0/0"
      NatGatewayId: !Ref vpcNgw
  srta1Ngw:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub1Private
      RouteTableId: !Ref rtbNat
  srta2Ngw:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub2Private
      RouteTableId: !Ref rtbNat
  srta3Ngw:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub3Private
      RouteTableId: !Ref rtbNat

## Create VPC S3 endpoint
  s3Enpoint:
    Type: "AWS::EC2::VPCEndpoint"
    Properties:
      VpcId: !Ref vpc
      ServiceName: !Sub "com.amazonaws.${AWS::Region}.s3"
      RouteTableIds:
        - !Ref rtbPublic
        - !Ref rtbNat
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Principal: "*"
            Effect: Allow
            Action: "s3:*"
            Resource:
              - "arn:aws:s3:::*"
              - "arn:aws:s3:::*/*"

## Create S3 bucket that will host lab resources (incl ML training data), if the ML lab condition allows it.
  bucketLabData:
    Type: "AWS::S3::Bucket"
    Properties:
      BucketName: !Join
        - "-"
        - - "auroralab"
          - data
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref 'AWS::StackId'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: TRUE
        BlockPublicPolicy: TRUE
        IgnorePublicAcls: TRUE
        RestrictPublicBuckets: TRUE
      Tags:
        - Key: Name
          Value: !Join
            - "-"
            - - "auroralab"
              - data
              - !Select
                - 0
                - !Split
                  - "-"
                  - !Select
                    - 2
                    - !Split
                      - "/"
                      - !Ref 'AWS::StackId'

## Create DB subnet group
  dbSubnets:
    Type: "AWS::RDS::DBSubnetGroup"
    Properties:
      DBSubnetGroupName: !If [ IsWS, "auroralab-db-subnet-group",!Join ['-', ['auroralab-db-subnet-group', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      DBSubnetGroupDescription: "Aurora Lab subnets allowed for deploying DB instances"
      SubnetIds: [ !Ref sub1Private, !Ref sub2Private, !Ref sub3Private ]
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-db-subnet-group", !Join ['-', ['auroralab-db-subnet-group', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create client security group
  clientSecGroup:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      VpcId: !Ref vpc
      GroupName: !If [ IsWS, "auroralab-workstation-sg", !Join ['-', ['auroralab-workstation-sg', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      GroupDescription: "Aurora lab workstation security group (firewall)"
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-workstation-sg", !Join ['-', ['auroralab-workstation-sg', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create DB security group
  dbClusterSecGroup:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      VpcId: !Ref vpc
      GroupName:  !If [ IsWS, "auroralab-database-sg", !Join ['-', ['auroralab-database-sg', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      GroupDescription: "Aurora lab database security group (firewall)"
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-database-sg", !Join ['-', ['auroralab-database-sg', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          SourceSecurityGroupId: !Ref clientSecGroup
          Description: "Allows MySQL access from the workstation security group"
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          SourceSecurityGroupId: !Ref clientSecGroup
          Description: "Allows PG access from the workstation security group"
  ruleDbClusterSecGroupIngressSelf:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref dbClusterSecGroup
      IpProtocol: -1
      Description: "Allows all inbound access from sources with the same security group"
      SourceSecurityGroupId: !Ref dbClusterSecGroup




## Create a random generated password and store it as a secret for the DB cluster
  secretClusterAdminUser:
    Type: "AWS::SecretsManager::Secret"
    Properties:
      Description: "Administrator user credentials for DB cluster 'auroralab-mysql-cluster'"
      GenerateSecretString:
        SecretStringTemplate: '{"username": "administrator"}'
        GenerateStringKey: 'password'
        PasswordLength: 10
        ExcludeCharacters: '="@/\$`&:{}()[];'
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-cluster-secret", !Join ['-', ['auroralab-cluster-secret', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]


## Create enhanced monitoring role
  roleEnhancedMonitoring:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !If [ IsWS, !Sub "auroralab-monitor-${AWS::Region}", !Join ['-', ['auroralab-monitor', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Description: "Allows your Aurora DB cluster to deliver Enhanced Monitoring metrics."
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "sts:AssumeRole"
            Principal:
              Service:
                - "monitoring.rds.amazonaws.com"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole"
      Tags:
        - Key: Name
          Value: !If [ IsWS, !Sub "auroralab-monitor-${AWS::Region}", !Join ['-', ['auroralab-monitor', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

  ## Create StackSet Admin Role. Do not change role names. Must be exactly as below.
  StackSetAdministrationRole:
    Type: AWS::IAM::Role
    DependsOn: StackSetExecutionRole
    Properties:
      RoleName:  !If [ IsWS, !Sub "AWSCloudFormationStackSetAdministrationRole",!Join ['-', ['AWSCloudFormationStackSetAdministrationRole', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: cloudformation.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: auroralab-StackSetAdminRolePolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - sts:AssumeRole
                Resource:
                  - "arn:*:iam::*:role/AWSCloudFormationStackSetExecutionRole"

  ## Create StackSet execution role. Do not change role names. Must be exactly as below.
  StackSetExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !If [ IsWS, !Sub "AWSCloudFormationStackSetExecutionRole",!Join ['-', ['AWSCloudFormationStackSetExecutionRole', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              AWS:
                - !Ref "AWS::AccountId"
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: auroralab-StackSetExecutionRolePolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "cloudformation:*"
                  - "cloudwatch:*"
                  - "cloud9:*"
                  - "ec2:*"
                  - "events:*"
                  - "iam:*"
                  - "kms:*"
                  - "kinesis:*"
                  - "lambda:*"
                  - "logs:*"
                  - "rds:*"
                  - "rds-data:*"
                  - "rds-db:*"
                  - "s3:*"
                  - "secretsmanager:*"
                  - "sns:*"
                  - "ssm:*"
                  - "ssmmessages:*"
                  - "sts:*"
                  - "pi:*"
                  - "sagemaker:*"
                Resource:
                  - "*"
## Create external integration role
  roleServiceIntegration:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !If [ IsWS, !Sub "auroralab-integrate-${AWS::Region}", !Join ['-', ['auroralab-integrate', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Description: "Allows your Aurora DB cluster to integrate with other AWS services, such as Amazon S3 for import/export."
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "sts:AssumeRole"
            Principal:
              Service:
                - "rds.amazonaws.com"
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "s3:ListBucket"
                  - "s3:GetObject"
                  - "s3:GetObjectVersion"
                  - "s3:AbortMultipartUpload"
                  - "s3:DeleteObject"
                  - "s3:ListMultipartUploadParts"
                  - "s3:PutObject"
                Resource:
                  - "arn:aws:s3:::*/*"
                  - "arn:aws:s3:::*"
      Tags:
        - Key: Name
          Value: !If [ IsWS, !Sub "auroralab-integrate-${AWS::Region}", !Join ['-', ['auroralab-integrate', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create fault injection role to call Aurora RDS APIs and CW Logs
  roleFaultInjection:
      Type: "AWS::IAM::Role"
      Properties:
        RoleName: !If [ IsWS, !Sub "auroralab-fis", !Join ['-', ['auroralab-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
        Description: "Allows FIS service to call Aurora Failover and Reboot APIs. Also push logs to CW logs."
        AssumeRolePolicyDocument:
          Version: 2012-10-17
          Statement:
            - Effect: Allow
              Action:
                - "sts:AssumeRole"
              Principal:
                Service:
                  - "fis.amazonaws.com"
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/service-role/AWSFaultInjectionSimulatorRDSAccess"
          - "arn:aws:iam::aws:policy/AmazonSSMFullAccess"
        Policies:
          - PolicyName: inline-policy-fis
            PolicyDocument:
              Version: 2012-10-17
              Statement:
                - Effect: Allow
                  Action:
                    - "logs:PutResourcePolicy"
                    - "logs:DescribeResourcePolicies"
                    - "logs:DescribeLogGroups"
                    - "logs:CreateLogStream"
                    - "logs:CreateLogDelivery"
                    - "logs:CreateLogGroup"
                    - "logs:DeleteLogGroup"
                    - "logs:DeleteLogStream"
                    - "logs:CreateLogStream"
                    - "logs:DeleteLogDelivery"
                  Resource:
                    - "*"
        Tags:
          - Key: Name
            Value: !If [ IsWS, !Sub "auroralab-fis", !Join ['-', ['auroralab-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create role for client IDE
  roleClientIDE:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !If [ IsWS, !Sub "auroralab-ide-${AWS::Region}", !Join ['-', ['auroralab-ide', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Description: "Permits user interaction with AWS APIs from the Cloud9 IDE."
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "sts:AssumeRole"
            Principal:
              Service:
                - "ec2.amazonaws.com"
                - "ssm.amazonaws.com"
                - "cloud9.amazonaws.com"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
        - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
        - "arn:aws:iam::aws:policy/AWSGlueConsoleSageMakerNotebookFullAccess"
        - "arn:aws:iam::aws:policy/AWSCloud9SSMInstanceProfile"
        - "arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess"
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "rds:*"
                  - "s3:*"
                  - "ssm:*"
                  - "kinesis:*"
                  - "kms:*"
                  - "sns:*"
                  - "secretsmanager:*"
                  - "rds-db:connect"
                  - "ec2:CreateVpcPeeringConnection"
                  - "ec2:DescribeVpcPeeringConnections"
                  - "ec2:ModifyVolume"
                  - "ec2:ModifyVolumeAttribute"
                  - "ec2:DescribeVolumesModifications"
                  - "ec2:AcceptVpcPeeringConnection"
                  - "ec2:DescribeRegions"
                  - "lambda:UpdateFunctionCode"
                  - "lambda:UpdateFunctionConfiguration"
                  - "iam:AttachRolePolicy"
                  - "iam:DetachRolePolicy"
                  - "iam:PutRolePolicy"
                  - "iam:DeleteRolePolicy"
                  - "iam:GetRolePolicy"
                  - "iam:CreatePolicy"
                  - "iam:DeletePolicy"
                  - "iam:CreateRole"
                  - "iam:DeleteRole"
                  - "iam:ListPolicies"
                  - "iam:ListRoles"
                  - "iam:PassRole"
                  - "fis:*"
                Resource: "*"
      Tags:
        - Key: Name
          Value: !If [ IsWS, !Sub "auroralab-ide-${AWS::Region}", !Join ['-', ['auroralab-ide', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
  profileClientIDE:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      InstanceProfileName: !If [ IsWS, !Sub "auroralab-ide-${AWS::Region}", !Join ['-', ['auroralab-ide', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${AWS::Region}"]]]
      Path: /
      Roles:
        - Ref: roleClientIDE

  loggroup:
    Type: AWS::Logs::LogGroup
    Properties: 
      LogGroupName: !If [ IsWS, "/aws/fis/aurora-fis", !Join ['-', ['/aws/fis/aurora-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Tags: 
        - Key: Name
          Value: !If [ IsWS, "/aws/fis/aurora-fis", !Join ['-', ['/aws/fis/aurora-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
## Create a Cloud9 IDE host
  c9ClientIDE:
    Type: AWS::Cloud9::EnvironmentEC2
    DependsOn: [ resLabAccount ]
    Properties: 
      AutomaticStopTimeMinutes: 120
      ConnectionType: CONNECT_SSM
      Description: "Cloud9 IDE to interact with the Aurora DB resources"
      InstanceType: !FindInMap [ RegionalSettings, !Ref "AWS::Region", ideType ]
      ImageId: resolve:ssm:/aws/service/cloud9/amis/amazonlinux-2-x86_64
      Name: !If [ IsWS, "auroralab-client-ide",!Join ['-', ['auroralab-client-ide', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      SubnetId: !Ref sub1Private
      OwnerArn: !If [ IsWS, !Sub "arn:aws:sts::${AWS::AccountId}:assumed-role/WSParticipantRole/Participant", Ref: AWS::NoValue ]
      Tags:
        - Key: BootstrapGroup
          Value: !Join ['-', ['bootstrap', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]

## Create a Cloud9 host SSM bootstrap document
  ssmDocClientBootstrap: 
    Type: AWS::SSM::Document
    DependsOn: [ bootstrapWaitHandle ]
    Properties:
      DocumentType: Command
      Name: !If [ IsWS, "auroralab-bootstrap-client", !Join ['-', ['auroralab-bootstrap-client', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-bootstrap-client", !Join ['-', ['auroralab-bootstrap-client', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Content:
        schemaVersion: '2.2'
        description: "Bootstrap Cloud9 Client IDE Instance"
        mainSteps:
        - action: aws:runShellScript
          name: BootstrapTools
          inputs:
            runCommand:
            - "#!/bin/bash -xe"
            - "exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1"
            - "echo \"$(date \"+%F %T\") * running as $(whoami)\" >> /bootstrap.log"
            - "yum install -y unzip jq"
            - "echo \"$(date \"+%F %T\") * upgrading Python 3\" >> /bootstrap.log"
            - "curl -O https://www.python.org/ftp/python/3.9.17/Python-3.9.17.tgz;tar xvf Python-3.9.17.tgz;tar xvf Python-3.9.17.tgz"
            - "cd Python-3.9.17"
            - "./configure --enable-optimizations;sudo make altinstall"
            - "update-alternatives --install /usr/bin/python3 python3 /usr/local/bin/python3.9 1"
            - "python3 -m pip install --upgrade pip"
            - "echo \"$(date \"+%F %T\") * python version\" >> /bootstrap.log"
            - "python3 --version >> /bootstrap.log"
            # - "sudo pip3 uninstall awscli -y"
            # - "sudo rm -r /usr/bin/aws -f"
            - "echo \"$(date \"+%F %T\") * installed supporting packages\" >> /bootstrap.log"
            # - "mkdir /home/ec2-user/awscl"
            # - "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"/home/ec2-user/awscl/awscliv2.zip\""
            # - "unzip \"/home/ec2-user/awscl/awscliv2.zip\" -d \"/home/ec2-user/awscl\""
            # - "sudo chown ec2-user:ec2-user /home/ec2-user/awscl/aws -R"
            # - "sudo /home/ec2-user/awscl/aws/install -i /usr/local/aws-cli -b /usr/local/bin"
            # - "echo \"$(date \"+%F %T\") * installed awscli (v2)\" >> /bootstrap.log"
            - "yum remove -y mariadb"
            - "yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm"
            - "percona-release disable all"
            - "percona-release setup pt"
            - "percona-release setup ps80"
            - "yum install -y percona-toolkit percona-server-client"
            - "mysql --version >> /bootstrap.log"
            - "echo \"$(date \"+%F %T\") * installed Percona tools and client libraries\" >> /bootstrap.log"
            - "curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash"
            - "yum -y install sysbench"
            - "sysbench --version >> /bootstrap.log"
            - "echo \"$(date \"+%F %T\") * installed Sysbench\" >> /bootstrap.log"
            - "git clone https://github.com/Percona-Lab/sysbench-tpcc.git /home/ec2-user/environment/sysbench-tpcc"
            - "echo \"$(date \"+%F %T\") * cloned percona/sysbench-tpcc repo\" >> /bootstrap.log"
            - "git clone https://github.com/datacharmer/test_db.git /home/ec2-user/environment/samples"
            - "echo \"$(date \"+%F %T\") * cloned sample data repo\" >> /bootstrap.log"
            - "cd /home/ec2-user/environment"
            - "curl -O https://ams-labs-prod-content-us-east-1.s3.amazonaws.com/support/client-requirements.txt"
            - "pip3 install -r client-requirements.txt"             
            - "echo \"$(date \"+%F %T\") * downloaded lab assets\" >> /bootstrap.log"
            - "mkdir -p /home/ec2-user/.aws"
            - "touch /home/ec2-user/.aws/config"
            - "echo \"[default]\" >> /home/ec2-user/.aws/config"
            - !Sub "echo \"region = ${AWS::Region}\" >> /home/ec2-user/.aws/config"
            - "chown -R ec2-user:ec2-user /home/ec2-user/.aws"
            - "aws --version >> /bootstrap.log"
            - "echo \"$(date \"+%F %T\") * configured aws cli\" >> /bootstrap.log"
            - 'export ANALYTICSURI="https://e6oqcsgjei.execute-api.us-east-1.amazonaws.com/v1/track" && echo "export ANALYTICSURI=\"$ANALYTICSURI\"" >> /home/ec2-user/.bashrc'
            - !Sub 'export STACKREGION="${AWS::Region}" && echo "export STACKREGION=\"$STACKREGION\"" >> /home/ec2-user/.bashrc'
            - !Sub 'export STACKNAME="${AWS::StackName}" && echo "export STACKNAME=\"$STACKNAME\"" >> /home/ec2-user/.bashrc'
            - Fn::Join:
              - ""
              - - 'export STACKUUID="'
                - !Select
                  - 2
                  - !Split
                    - "/"
                    - !Ref 'AWS::StackId'
                - '" && echo "export STACKUUID=\"$STACKUUID\"" >> /home/ec2-user/.bashrc'
            - !Sub 'export DATABUCKET="${bucketLabData}" && echo "export DATABUCKET=\"$DATABUCKET\"" >> /home/ec2-user/.bashrc'
            - !Sub 'export DBCLUSTERPG="${cpgClusterParams3}" && echo "export DBCLUSTERPG=\"$DBCLUSTERPG\"" >> /home/ec2-user/.bashrc'
            - "echo \"$(date \"+%F %T\") * environment vars initialized\" >> /bootstrap.log"
            - !Sub "export SECRETSTRING=`aws secretsmanager get-secret-value --secret-id \"${secretClusterAdminUser}\" --region ${AWS::Region} | jq -r '.SecretString'` && export DBPASS=`echo $SECRETSTRING | jq -r '.password'` && export DBUSER=`echo $SECRETSTRING | jq -r '.username'`"
            - 'echo "export DBPASS=\"$DBPASS\"" >> /home/ec2-user/.bashrc && echo "export DBUSER=$DBUSER" >> /home/ec2-user/.bashrc'
            - 'echo "export PGPASSWORD=\"$DBPASS\"" >> /home/ec2-user/.bashrc && echo "export PGUSER=$DBUSER" >> /home/ec2-user/.bashrc'
            - "chown -R ec2-user:ec2-user /home/ec2-user/environment/*"
            - "echo \"$(date \"+%F %T\") * updated file ownership\" >> /bootstrap.log"
            - "echo \"$(date \"+%F %T\") * resizing local storage\" >> /bootstrap.log"
            - "curl -O https://ams-labs-prod-content-us-east-1.s3.amazonaws.com/support/resize.sh"
            - "chown -R ec2-user:ec2-user /home/ec2-user/environment/*"  
            - sudo yum install -y jq &>> /bootstrap.log
            - sudo amazon-linux-extras enable postgresql14 &>> /bootstrap.log
            - sudo yum clean metadata && sudo yum install -y postgresql-contrib postgresql postgresql-devel libpq-devel sysbench &>> /bootstrap.log
            - sudo yum install -y gcc gcc-devel python3-devel initscripts &>> /bootstrap.log
            - echo "$(date "+%F %T") - Step 2 - Exporting the required environment variables" >> /bootstrap.log
            - !Sub REGION=${AWS::Region}
            - echo "export PGDATABASE=mylab" >> /home/ec2-user/.bashrc
            - !If
              - IsWS
              - !Sub "aws s3 cp s3://${MyAssetsBucketName}/${MyAssetsBucketPrefix}fis/monitoring.sh monitoring.sh"
              - echo "yet to work on CFN"
            - !If
              - IsWS
              - !Sub "aws s3 cp s3://${MyAssetsBucketName}/${MyAssetsBucketPrefix}fis/fis-aurora-chaos-experiment.json fis-aurora-chaos-experiment.json"
              - echo "yet to work on CFN"
            - !If
              - IsWS
              - !Sub "aws s3 cp s3://${MyAssetsBucketName}/${MyAssetsBucketPrefix}fis/fis-aurora-reboot-experiment.json fis-aurora-reboot-experiment.json"
              - echo "yet to work on CFN"
            - !If
              - IsWS
              - !Sub "aws s3 cp s3://${MyAssetsBucketName}/${MyAssetsBucketPrefix}fis/fis-aurora-fault-injection.json fis-aurora-fault-injection.json"
              - echo "yet to work on CFN"
            - "bash /home/ec2-user/environment/resize.sh 100"
            - !Sub "curl -X PUT -H 'Content-Type:' --data-binary '{\"Status\": \"SUCCESS\", \"Reason\": \"Bootstrap complete\", \"UniqueId\": \"${AWS::StackId}\", \"Data\": \"Bootstrap complete\"}' \"${bootstrapWaitHandle}\""
            - "echo \"$(date \"+%F %T\") * signal bootstrap complete\" >> /bootstrap.log"
            - "shutdown -r now"

## Create a Cloud9 host SSM bootstrap document
  ssmDocClientFIS: 
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Name: !If [ IsWS, "auroralab-postgres-fis", !Join ['-', ['auroralab-postgres-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-postgres-fis", !Join ['-', ['auroralab-postgres-fis', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Content:
        schemaVersion: '2.2'
        description: "SSM document for fault injection queries"
        parameters:
          ActionType:
            type: String
        mainSteps:
        - action: aws:runShellScript
          name: aurorafis
          inputs:
            runCommand:
                - |
                  #!/bin/bash
                  export actionType={{ ActionType }}
                  function setEnv  
                  {
                      export AWSREGION=`aws ec2 describe-availability-zones --output text --query 'AvailabilityZones[0].[RegionName]'`
                      export CLUSTERENDP=`aws rds describe-db-clusters --region $AWSREGION --query "DBClusters[?starts_with(DBClusterIdentifier, 'auroralab-pg-cluster')].Endpoint" --output text`
                      export READERENDP=`aws rds describe-db-clusters --region $AWSREGION --query "DBClusters[?starts_with(DBClusterIdentifier, 'auroralab-pg-cluster')].ReaderEndpoint" --output text`
                      export SECRETARN=`aws secretsmanager list-secrets --query "SecretList[?starts_with(Name, 'secretClusterAdminUser')].ARN"  --region $AWSREGION --output text`
                      export CREDS=`aws secretsmanager get-secret-value --secret-id $SECRETARN --region $AWSREGION | jq -r '.SecretString'`
                      export READONLYNODE=`aws rds describe-db-clusters --query "DBClusters[?starts_with(DBClusterIdentifier, 'auroralab-pg-cluster')].DBClusterMembers" --output json | jq '.[][] | select(.IsClusterWriter == false) | .DBInstanceIdentifier' |  tr -d '"'| shuf -n 1`
                      export DBUSER="`echo $CREDS | jq -r '.username'`"
                      export DBPASS="`echo $CREDS | jq -r '.password'`"
                      export PGPASSWORD="$DBPASS"
                      export PGUSER="$DBUSER"
                      export PGDATABASE=mylab
                  }
                  function instancecrash
                  {
                    echo "Starting instance crash on ${READERENDP} at `date`"       
                    psql -h ${READERENDP} -c "SELECT aurora_inject_crash ('node')" > /dev/null 2>&1
                    echo "Instance crash completed on ${READERENDP} at `date`"
                  }
                  function replicafailure
                  {
                    echo "Initiating Replica failure on ${READONLYNODE} at `date`"
                    psql -h ${CLUSTERENDP} -c "SELECT aurora_inject_replica_failure(100, 60,'$READONLYNODE')" 
                    echo "Replica failure completed on ${READONLYNODE} at `date`"
                  }
                  function diskfailure
                  {
                    echo "Initiating disk congestion on ${CLUSTERENDP} at `date`"
                    psql -h ${CLUSTERENDP} -c "SELECT aurora_inject_disk_failure(100, -1, true, 20)" 
                    echo "Disk Congestion completed on ${CLUSTERENDP} at `date`"	
                  }
                  setEnv
                  if [ "$actionType" = "chaos" ]; then
                    # AWS SSM parameter name
                    parameter_name="/fis/random_choice"
                    # Array of choices
                    choices=("instancecrash" "replicafailure" "diskcongestion")
                    # Get the previous choice from AWS SSM Parameter Store
                    previous_choice=$(aws ssm get-parameter --name "$parameter_name" --query "Parameter.Value" --output text 2>/dev/null)
                    echo "previous selection $previous_choice"
                    new_choices=()
                    # Iterate through the original array and add elements to the new array
                    for choice in "${choices[@]}"; do
                      if [[ "$choice" != "$previous_choice" ]]; then
                        new_choices+=("$choice")
                      fi
                    done
                    # Get the length of the array
                    length=${#new_choices[@]}
                    
                    # Generate a random index
                    random_index=$((RANDOM % length))
                    
                    # Get the random choice
                    random_choice=${new_choices[random_index]}
                    echo "current selection $random_choice"
                    
                    # Store the current choice in AWS SSM Parameter Store
                    aws ssm put-parameter --name "$parameter_name" --value "$random_choice" --type "String" --overwrite
                    actionType=$random_choice
                  fi
                  case ${actionType} in
                      "instancecrash")
                          instancecrash
                          ;;
                      "replicafailure")
                          replicafailure
                          ;;
                      "diskcongestion")
                          diskcongestion
                          ;;
                      *)
                          echo "Invalid Action"
                          ;;
                  esac

## Create cluster parameter group for Aurora MySQL 3
  cpgClusterParams3:
    Type: "AWS::RDS::DBClusterParameterGroup"
    Properties:
      Description:  !If [ IsWS, "auroralab-mysql3-cluster-params", !Join ['-', ['auroralab-mysql3-cluster-params', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Family: !FindInMap [ ClusterSettings, global, dbFamilyAMS3 ]
      Parameters:
        aws_default_s3_role: !GetAtt roleServiceIntegration.Arn
        innodb_stats_persistent_sample_pages: "256"
        slow_query_log: "1"
        long_query_time: "1"
        log_output: FILE
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-mysql3-cluster-params", !Join ['-', ['auroralab-mysql3-cluster-params', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]


### !!!WARNING :  DO NOT DELETE THIS COMMENT BLOCK. It will affect stackset processing functionality.
##STACKSETBLOCKSTART
## Creates Aurora stack for deploying Global Database in secondary region

##STACKSETBLOCKEND
### !!!WARNING :  DO NOT DELETE THIS COMMENT BLOCK. It will affect stackset processing functionality.

## Create parameter groups for APG cluster nodes

  apgcustomdbparamgroup:
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Description: !Sub ${TemplateName}-dbparamgroup
      Family: !FindInMap [ ClusterSettings, global, pgdbFamily ]
      Parameters:
        log_rotation_age: '1440'
        log_rotation_size: '102400'
      Tags:
        - Key: Name
          Value: !Sub ${TemplateName}-dbparamgroup

 ## Create cluster parameter group for apg
  apgcustomclusterparamgroup:
    Type: AWS::RDS::DBClusterParameterGroup
    Properties:
      Description: !Sub ${TemplateName}-clusterparamgroup
      Family: !FindInMap [ ClusterSettings, global, pgdbFamily ]
      Parameters:
        rds.force_ssl: 0
        shared_preload_libraries: 'pg_stat_statements,pg_hint_plan,auto_explain'
      Tags:
        - Key: Name
          Value: !Sub ${TemplateName}-clusterparamgroup

 ## Create Aurora PostgreSQL cluster
  dbClusterapg:
    Type: AWS::RDS::DBCluster
    Properties:
      Engine: aurora-postgresql
      EngineVersion : !Ref DBEngineVersion
      Port: 5432
      DBSubnetGroupName: !Ref dbSubnets
      DBClusterParameterGroupName: !Ref apgcustomclusterparamgroup
      DBClusterIdentifier:  !If [ IsWS, "auroralab-pg-cluster", !Join ['-', ['auroralab-pg-cluster', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      BackupRetentionPeriod: 7
      MasterUsername: !Join ['', ['{{resolve:secretsmanager:', !Ref secretClusterAdminUser, ':SecretString:username}}' ]]
      MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref secretClusterAdminUser, ':SecretString:password}}' ]]
      DatabaseName: !FindInMap [ ClusterSettings, global, dbSchema ]
      StorageEncrypted: true
      VpcSecurityGroupIds: [ !Ref dbClusterSecGroup ]
      Tags:
        - Key: Name
          Value: !Sub ${TemplateName}-cluster
## Deploy the first cluster node (always the writer)
  dbNodeWriter:
    Type: AWS::RDS::DBInstance
    Properties:
      DBClusterIdentifier: !Ref dbClusterapg
      DBInstanceIdentifier:  !If [ IsWS, "auroralab-pg-node-1", !Join ['-', ['auroralab-pg-node-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !Ref DBInstanceClass
      DBParameterGroupName: !Ref apgcustomdbparamgroup
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: aurora-postgresql
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AutoMinorVersionUpgrade: false
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az1 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pg-node-1", !Join ['-', ['auroralab-pg-node-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
## Deploy a reader node
  dbNodeSecondary:
    Type: AWS::RDS::DBInstance
    Properties:
      DBClusterIdentifier: !Ref dbClusterapg
      DBInstanceIdentifier:  !If [ IsWS, "auroralab-pg-node-2", !Join ['-', ['auroralab-pg-node-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !Ref DBInstanceClass
      DBParameterGroupName: !Ref apgcustomdbparamgroup
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: aurora-postgresql
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AutoMinorVersionUpgrade: false
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az2 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pg-node-2", !Join ['-', ['auroralab-pg-node-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Deploy a reader node
  dbNodetertiary:
    Type: AWS::RDS::DBInstance
    Properties:
      DBClusterIdentifier: !Ref dbClusterapg
      DBInstanceIdentifier: !If [ IsWS, "auroralab-pg-node-3", !Join ['-', ['auroralab-pg-node-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !Ref DBInstanceClass
      DBParameterGroupName: !Ref apgcustomdbparamgroup
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: aurora-postgresql
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AutoMinorVersionUpgrade: false
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az3 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-pg-node-3", !Join ['-', ['auroralab-pg-node-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Create Aurora MySQL 3 cluster
  dbCluster:
    Type: "AWS::RDS::DBCluster"
    DeletionPolicy: Delete
    Condition: IsMySQL
    Properties:
      Engine: !FindInMap [ ClusterSettings, global, dbEngine ]
      EngineVersion: !FindInMap [ ClusterSettings, global, dbVersionAMS3 ]
      DBSubnetGroupName: !Ref dbSubnets
      DBClusterParameterGroupName: !Ref cpgClusterParams3
      DBClusterIdentifier: !If [ IsWS, "auroralab-mysql-cluster", !Join ['-', ['auroralab-mysql-cluster', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      BackupRetentionPeriod: 1
      MasterUsername: !Join ["", ["{{resolve:secretsmanager:", !Ref secretClusterAdminUser, ":SecretString:username}}" ]]
      MasterUserPassword: !Join ["", ["{{resolve:secretsmanager:", !Ref secretClusterAdminUser, ":SecretString:password}}" ]]
      DatabaseName: !FindInMap [ ClusterSettings, global, dbSchema ]
      StorageEncrypted: true
      VpcSecurityGroupIds: [ !Ref dbClusterSecGroup ]
      EnableCloudwatchLogsExports: [ error, slowquery ]
      #KmsKeyId: !GetAtt dbclusterkey.Arn
      EnableIAMDatabaseAuthentication: true
      AssociatedRoles:
        - RoleArn: !GetAtt roleServiceIntegration.Arn
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-mysql-cluster", !Join ['-', ['auroralab-mysql-cluster', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
## Deploy cluster node #1 (may or may not be writer depending which one initializes first)
  dbNode1:
    Type: "AWS::RDS::DBInstance"
    DeletionPolicy: Delete
    Condition: IsMySQL
    Properties:
      DBClusterIdentifier: !If [ IsMySQL, !Ref dbCluster,""]
      DBInstanceIdentifier:  !If [ IsWS, "auroralab-mysql-node-1", !Join ['-', ['auroralab-mysql-node-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !FindInMap [ RegionalSettings, !Ref "AWS::Region", nodeType ]
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: !FindInMap [ ClusterSettings, global, dbEngine ]
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az1 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-mysql-node-1", !Join ['-', ['auroralab-mysql-node-1', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
## Deploy cluster node #2 (may or may not be writer depending which one initializes first)
  dbNode2:
    Type: "AWS::RDS::DBInstance"
    DeletionPolicy: Delete
    Condition: IsMySQL
    Properties:
      DBClusterIdentifier: !If [ IsMySQL, !Ref dbCluster,""]
      DBInstanceIdentifier:  !If [ IsWS, "auroralab-mysql-node-2", !Join ['-', ['auroralab-mysql-node-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !FindInMap [ RegionalSettings, !Ref "AWS::Region", nodeType ]
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: !FindInMap [ ClusterSettings, global, dbEngine ]
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az2 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-mysql-node-2", !Join ['-', ['auroralab-mysql-node-2', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]

## Deploy cluster node #3 (may or may not be writer depending which one initializes first)
  dbNode3:
    Type: "AWS::RDS::DBInstance"
    DeletionPolicy: Delete
    Condition: IsMySQL
    Properties:
      DBClusterIdentifier: !If [ IsMySQL, !Ref dbCluster,""]
      DBInstanceIdentifier:  !If [ IsWS, "auroralab-mysql-node-3", !Join ['-', ['auroralab-mysql-node-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      CopyTagsToSnapshot: true
      DBInstanceClass: !FindInMap [ RegionalSettings, !Ref "AWS::Region", nodeType ]
      CACertificateIdentifier: "rds-ca-rsa2048-g1"
      Engine: !FindInMap [ ClusterSettings, global, dbEngine ]
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AvailabilityZone: !FindInMap [ RegionalSettings, !Ref "AWS::Region", az3 ]
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-mysql-node-3", !Join ['-', ['auroralab-mysql-node-3', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]



## Role to overcome current limitations in CFN ScalableTarget implemetation
## This role is *NOT* actively used by any resource and service, but must be present

## Register the scalable target
## Bug fix: when the stack name contains uppercase letters,
## the DB cluster identifier is actually lowercased, but the resource ID
## still contains uppercase, so you get a mismatch on the scalable target ResourceId


## Add scaling policy


## Create sysbench prep SSM document

## Create a Sagemaker Lifecycle hook, which will clone the github repo and get the Jupyter notebook and other resources needed to build the model.
## using nohup, so the script keeps running after 5 minutes. The onstart event fails, if script doesn't finish in 5 minutes.


## Create role for use with the lab support function
  roleLabSupport:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !If [ IsWS, !Sub "auroralab-support-${AWS::Region}", !Join ['-', ['auroralab-support', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${AWS::Region}"]]]
      Description: "Role to permit the Lambda support functions to interact with relevant AWS APIs."
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "sts:AssumeRole"
            Principal:
              Service:
                - "lambda.amazonaws.com"
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"
              - Effect: Allow
                Action:
                  - cloudformation:DescribeStacks
                  - cloudformation:DescribeStackEvents
                  - cloudformation:DescribeStackResource
                  - cloudformation:DescribeStackResources
                  - ec2:DescribeInstances
                  - ec2:AssociateIamInstanceProfile
                  - ec2:ModifyInstanceAttribute
                  - ec2:ReplaceIamInstanceProfileAssociation
                  - ec2:DescribeIamInstanceProfileAssociations
                  - ec2:DisassociateIamInstanceProfile
                  - ec2:ModifyInstanceAttribute
                  - ec2:ReplaceIamInstanceProfileAssociation
                  - ec2:CreateNetworkInterface
                  - ec2:DescribeNetworkInterfaces
                  - ec2:DeleteNetworkInterface
                  - iam:ListInstanceProfiles
                  - iam:PassRole
                  - ssm:DescribeInstanceInformation
                  - ssm:SendCommand
                  - cloud9:UpdateEnvironment
                  - cloud9:UpdateEnvironmentSettings
                  - cloud9:DescribeEnvironments
                  - cloud9:ListEnvironments
                  - cloudwatch:PutMetricData
                  - cloudwatch:ListMetrics
                  - cloudwatch:GetMetricData
                Resource: "*"
      Tags:
        - Key: Name
          Value:  !If [ IsWS, !Sub "auroralab-support-${AWS::Region}", !Join ['-', ['auroralab-support', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${AWS::Region}"]]]

## Create Lambda function to implement support operations
  funcLabSupport:
    Type: "AWS::Lambda::Function"
    DependsOn: [ c9ClientIDE ]
    Properties:
      FunctionName: !If [ IsWS, "auroralab-support", !Join ['-', ['auroralab-support', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Description: "Custom Resource to provide support operations for the Aurora MySQL labs."
      Handler: "index.handler"
      Role: !GetAtt roleLabSupport.Arn
      Runtime: "python3.9"
      Timeout: 600
      Tags:
        - Key: Name
          Value:  !If [ IsWS, "auroralab-support", !Join ['-', ['auroralab-support', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Environment:
        Variables:
          REGION: !Ref "AWS::Region"
          ANALYTICSURI: "https://e6oqcsgjei.execute-api.us-east-1.amazonaws.com/v1/track"
      Code:
        ZipFile: |
          # Dependencies
          from os import environ
          import cfnresponse
          import boto3
          import urllib3
          import json
          import datetime
          import time

          print("[INFO]", "Initialize function")
          session = boto3.session.Session(region_name=environ["REGION"])
          ide = session.resource('ec2')
          ec2 = session.client('ec2')
          ssm = session.client('ssm')
          cl9ide = session.client('cloud9')
          cfn = boto3.client('cloudformation', region_name=environ["REGION"])
          http = urllib3.PoolManager()

          # Lambda handler function / main function
          def handler(event, context):
            print("[INFO]", "Invocation start")

            # init response
            props = event["ResourceProperties"]
            response_status = cfnresponse.FAILED
            response_data = {}

            # try/catch
            try:
              # lowercase names, set response as success
              response_data["DBClusterId"] = props["Cluster"].lower()
              response_data["DBClusterScalableTarget"] = "cluster:%s" % response_data["DBClusterId"]
              print("[INFO]", "ScalableTarget computed:", response_data["DBClusterScalableTarget"])


              # on stack creation
              if event["RequestType"] == 'Create':
                # wait until Cloud9 instance is available
                print("[INFO]", "Instance filter to use:", props['IDEEnvTagName'])
                result = ec2.describe_instances(Filters=[{'Name': 'tag:Name','Values': [props['IDEEnvTagName']]}])
                if ('Reservations' in result and len(result['Reservations']) > 0):
                  c9 = result['Reservations'][0]['Instances'][0]
                  print("[INFO]", "Found IDE instance", c9['InstanceId'])
                  while c9['State']['Name'] != 'running':
                    time.sleep(5)
                    c9 = ec2.describe_instances(InstanceIds=[c9['InstanceId']])['Reservations'][0]['Instances'][0]

                  # swap the profiles
                  prof = {
                    'Arn': props['IDEProfileArn'],
                    'Name': props['IDEProfileName']
                  }

                  # find iam instance profile association
                  result = ec2.describe_iam_instance_profile_associations(
                    Filters=[{'Name': 'instance-id', 'Values': [c9['InstanceId']]}]
                  )
                  if ('IamInstanceProfileAssociations' in result and len(result['IamInstanceProfileAssociations']) > 0):
                    assoc = result['IamInstanceProfileAssociations'][0]
                    print("[INFO]", "Replacing IAM profile association:", assoc['AssociationId'])
                    response = ec2.replace_iam_instance_profile_association(IamInstanceProfile=prof, AssociationId=assoc['AssociationId'])
                  else:
                    print("[INFO]", "Associating new IAM profile")
                    response = ec2.associate_iam_instance_profile(IamInstanceProfile=prof, InstanceId=c9['InstanceId'])

                  # attach workstation security group
                  attached_sgs = [sg['GroupId'] for sg in ide.Instance(c9['InstanceId']).security_groups]
                  attached_sgs.append(props["IDESecGroupId"])
                  response = ide.Instance(c9['InstanceId']).modify_attribute(Groups=attached_sgs)
                  print("[INFO]", "Attached SGs:", attached_sgs)

                  # wait for ssm registration
                  status = 'Offline'
                  tries = 0
                  while status != 'Online' and tries < 50:
                    response = ssm.describe_instance_information(Filters=[{'Key': 'InstanceIds', 'Values': [c9['InstanceId']]}])
                    if ('InstanceInformationList' in response and len(response['InstanceInformationList']) > 0):
                      status = response['InstanceInformationList'][0]['PingStatus']
                    tries += 1
                    time.sleep(10)
                  
                  # run ssm bootstrap
                  if status == 'Online':
                    response = ssm.send_command(InstanceIds=[c9['InstanceId']],DocumentName=props["IDEBoostrapDoc"])
                    print("[INFO]", "Started IDE bootstrap:", response)
                  else:
                    print("[ERROR]", "Timeout exceeded waiting for SSM registration")
                
              # success
              response_status = cfnresponse.SUCCESS
              
            except Exception as e:
              print("[ERROR]", e)

            # try/catch
            try:
              # send response to CloudFormation
              cfnresponse.send(event, context, response_status, response_data)
            except Exception as e:
              print("[ERROR]", e)
              response_status = cfnresponse.FAILED
            print("[INFO]", "Invocation end")
            return response_status

## Custom resource to assign cluster IAM role
  resLabSupport:
    Type: "Custom::resLabSupport"
    Properties:
      ServiceToken: !GetAtt funcLabSupport.Arn
      StackRegion: !Ref "AWS::Region"
      StackName: !Ref "AWS::StackName"
      StackUUID: !Select
        - 2
        - !Split
          - "/"
          - !Ref "AWS::StackId"
      Cluster:  !Ref dbClusterapg
      IDEProfileArn: !GetAtt profileClientIDE.Arn
      IDEProfileName: !Ref profileClientIDE
      IDEEnvTagName: !If [ IsWS, !Sub "aws-cloud9-auroralab-client-ide-${c9ClientIDE}", !Join ['-', ['aws-cloud9-auroralab-client-ide', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${c9ClientIDE}"]]]
      IDESecGroupId: !Ref clientSecGroup
      IDEBoostrapDoc: !Ref ssmDocClientBootstrap

## Create role for use with the lab account function
  roleLabAccount:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !If [ IsWS, !Sub "auroralab-account-${AWS::Region}", !Join ['-', ['auroralab-account', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${AWS::Region}"]]]
      Description: "Role to permit the Lambda account functions to interact with relevant AWS APIs."
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "sts:AssumeRole"
            Principal:
              Service:
                - "lambda.amazonaws.com"
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"
              - Effect: Allow
                Action:
                  - "s3:ListBucket"
                  - "s3:GetObject"
                  - "s3:GetObjectVersion"
                  - "s3:DeleteObject"
                  - "s3:DeleteObjects"
                  - "s3:ListMultipartUploadParts"
                  - "s3:PutObject"
                  - "s3:ListObjects"
                  - "s3:ListObjectsV2"
                  - "s3:ListObjectVersions"
                Resource:
                  - !Sub "arn:aws:s3:::${bucketLabData}/*"
                  - !Sub "arn:aws:s3:::${bucketLabData}"
              - Effect: Allow
                Action:
                  - iam:CreateInstanceProfile
                  - iam:GetRole
                  - iam:PassRole
                  - iam:GetInstanceProfile
                  - iam:ListRoles
                  - iam:CreateRole
                  - iam:AttachRolePolicy
                  - iam:ListInstanceProfiles
                  - iam:AddRoleToInstanceProfile
                Resource: "*"
      Tags:
        - Key: Name
          Value: !If [ IsWS, !Sub "auroralab-account-${AWS::Region}", !Join ['-', ['auroralab-account', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]],!Sub "${AWS::Region}"]]]


## Create Lambda function to implement conditional initialization and cleanup of accounts
  funcLabAccount:
    Type: "AWS::Lambda::Function"
    DependsOn: [ bucketLabData ]
    Properties:
      FunctionName: !If [ IsWS, "auroralab-account", !Join ['-', ['auroralab-account', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Description: "Custom Resource to provide account initialization and cleanup for the Aurora MySQL labs."
      Handler: "index.handler"
      Role: !GetAtt roleLabAccount.Arn
      Runtime: "python3.9"
      Timeout: 600
      Tags:
        - Key: Name
          Value: !If [ IsWS, "auroralab-account", !Join ['-', ['auroralab-account', !Select [4, !Split ['-', !Select [2, !Split ['/', !Ref AWS::StackId]]]]]]]
      Environment:
        Variables:
          REGION: !Ref "AWS::Region"
      Code:
        ZipFile: |
          # Dependencies
          from os import environ
          import cfnresponse
          import boto3
          import urllib3
          import json
          import datetime
          import time

          print("[INFO]", "Initialize function")
          session = boto3.session.Session(region_name=environ["REGION"])
          s3 = session.resource('s3')
          iam = session.client('iam')

          # Lambda handler function / main function
          def handler(event, context):
            print("[INFO]", "Invocation start")

            # init response
            props = event["ResourceProperties"]
            response_status = cfnresponse.FAILED
            response_data = {}

            # try/catch
            try:
              # on stack creation
              if event["RequestType"] == 'Create':
                # does the Cloud9 standard role exist?
                missing = False
                try:
                  response = iam.get_role(RoleName='AWSCloud9SSMAccessRole')
                  print("[INFO]", "IAM role exists:", "AWSCloud9SSMAccessRole")
                except iam.exceptions.NoSuchEntityException:
                  missing = True
                except Exception as e:
                  print("[ERROR]", e)

                # create it if it doesn't exist
                if missing:
                  response = iam.create_role(
                    Path='/service-role/',
                    RoleName='AWSCloud9SSMAccessRole',
                    AssumeRolePolicyDocument='{"Version": "2012-10-17","Statement": [{"Effect": "Allow","Principal": {"Service": ["ec2.amazonaws.com","cloud9.amazonaws.com"]},"Action": "sts:AssumeRole"}]}'
                  )
                  response = iam.attach_role_policy(
                    RoleName='AWSCloud9SSMAccessRole',
                    PolicyArn='arn:aws:iam::aws:policy/AWSCloud9SSMInstanceProfile'
                  )
                  response = iam.attach_role_policy(
                      RoleName='AWSCloud9SSMAccessRole',
                      PolicyArn='arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore'
                  )
                  print("[INFO]", "Created IAM role:", "AWSCloud9SSMAccessRole")

                # does the Cloud9 standard instance profile exist?
                missing = False
                try:
                  response = iam.get_instance_profile(InstanceProfileName='AWSCloud9SSMInstanceProfile')
                  print("[INFO]", "IAM instance profile exists:", "AWSCloud9SSMInstanceProfile")
                except iam.exceptions.NoSuchEntityException:
                  missing = True
                except Exception as e:
                  print("[ERROR]", e)

                # create it if it doesn't exit
                if missing:
                  response = iam.create_instance_profile(
                    InstanceProfileName='AWSCloud9SSMInstanceProfile',
                    Path='/cloud9/'
                  )
                  response = iam.add_role_to_instance_profile(
                    InstanceProfileName='AWSCloud9SSMInstanceProfile',
                    RoleName='AWSCloud9SSMAccessRole'
                  )
                  print("[INFO]", "Created IAM instance profile:", "AWSCloud9SSMInstanceProfile")

              # on stack deletion
              if event["RequestType"] == 'Delete':
                # delete all objects out of the bucket
                bucket = s3.Bucket(props["DataBucket"])
                bucket.objects.delete()
                print("[INFO]", "Bucket cleaned up for:", props["DataBucket"])

              # success
              response_status = cfnresponse.SUCCESS

            except Exception as e:
              print("[ERROR]", e)

            # try/catch
            try:
              # send response to CloudFormation
              cfnresponse.send(event, context, response_status, response_data)
            except Exception as e:
              print("[ERROR]", e)
              response_status = cfnresponse.FAILED
            print("[INFO]", "Invocation end")
            return response_status

## Custom resource to implement initialization and cleanup of account
  resLabAccount:
    Type: "Custom::resLabAccount"
    Properties:
      ServiceToken: !GetAtt funcLabAccount.Arn
      DataBucket: !Ref bucketLabData
      StackRegion: !Ref "AWS::Region"
      StackName: !Ref "AWS::StackName"
      StackUUID: !Select
        - 2
        - !Split
          - "/"
          - !Ref "AWS::StackId"

## Wait condition to signal bootstrap completion
  bootstrapWaitHandle:
    Type: "AWS::CloudFormation::WaitConditionHandle"
  bootstrapWaitCondition:
    Type: "AWS::CloudFormation::WaitCondition"
    DependsOn: [ resLabSupport ]
    Properties: 
      Count: 1
      Handle: !Ref bootstrapWaitHandle
      Timeout: 900



## Outputs
Outputs:
  vpcId:
    Description: "Aurora Lab VPC"
    Value: !Ref vpc
  clientIdeUrl:
    Description: "Cloud9 Client IDE"
    Value: !Sub "https://${AWS::Region}.console.aws.amazon.com/cloud9/ide/${c9ClientIDE}?region=${AWS::Region}"
  clusterName:
    Description: "Aurora Cluster Name"
    Value: !Ref dbClusterapg
  clusterEndpoint:
    Description: "Aurora Cluster Endpoint"
    Value: !GetAtt dbClusterapg.Endpoint.Address
  readerEndpoint:
    Description: "Aurora Reader Endpoint"
    Value: !GetAtt dbClusterapg.ReadEndpoint.Address
  dbSubnetGroup:
    Description: "Database Subnet Group"
    Value: !Ref dbSubnets
  dbSecurityGroup:
    Description: "Database Security Group"
    Value: !Ref dbClusterSecGroup
  secretArn:
    Description: "Database Credentials Secret ARN"
    Value: !Ref secretClusterAdminUser


